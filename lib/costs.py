# lib/costs.py

from __future__ import annotations
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Any, Optional
import json
import math
import streamlit as st

# ============================================
# ç‚ºæ›¿ã®åˆæœŸå€¤ï¼ˆsecretsã«USDJPYãŒã‚ã‚Œã°ä¸Šæ›¸ãï¼‰
# ============================================
DEFAULT_USDJPY = float(st.secrets.get("USDJPY", 150.0))

# ============================================
# ãƒ¢ãƒ‡ãƒ«ä¾¡æ ¼ï¼ˆUSD / 100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
# ============================================
MODEL_PRICES_USD = {
    "gpt-5":         {"in": 1.25,  "out": 10.00},
    "gpt-5-mini":    {"in": 0.25,  "out": 2.00},
    "gpt-5-nano":    {"in": 0.05,  "out": 0.40},
    "gpt-4o":        {"in": 2.50,  "out": 10.00},
    "gpt-4o-mini":   {"in": 0.15,  "out": 0.60},
    "gpt-4.1":       {"in": 2.00,  "out": 8.00},   # å‚è€ƒ
    "gpt-4.1-mini":  {"in": 0.40,  "out": 1.60},   # å‚è€ƒ
    "gpt-3.5-turbo": {"in": 0.50,  "out": 1.50},   # å‚è€ƒ
}

# ============================================
# Embedding ä¾¡æ ¼ï¼ˆUSD / 100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
# ============================================
EMBEDDING_PRICES_USD = {
    "text-embedding-3-small": 0.02,
    "text-embedding-3-large": 0.13,
    "text-embedding-ada-002": 0.10,  # ãƒ¬ã‚¬ã‚·ãƒ¼
}

# ============================================
# éŸ³å£°ï¼ˆWhisperï¼‰ä¾¡æ ¼ï¼ˆUSD / åˆ†ï¼‰
# ============================================
AUDIO_PRICES_USD_PER_MIN = {
    "whisper-1": 0.006,   # $0.006 / åˆ†
}

MILLION = 1_000_000

@dataclass
class ChatUsage:
    input_tokens: int
    output_tokens: int

# å…±é€šï¼šUSDâ†’JPY å¤‰æ›
def usd_to_jpy(usd: float, rate: float = DEFAULT_USDJPY) -> float:
    return round(usd * rate, 2)

def estimate_chat_cost(model: str, usage: ChatUsage) -> dict:
    if model not in MODEL_PRICES_USD:
        raise ValueError(f"å˜ä¾¡æœªè¨­å®šã®ãƒ¢ãƒ‡ãƒ«: {model}")

    price = MODEL_PRICES_USD[model]
    in_cost  = (usage.input_tokens  / MILLION) * price["in"]
    out_cost = (usage.output_tokens / MILLION) * price["out"]
    usd = round(in_cost + out_cost, 6)
    jpy = usd_to_jpy(usd)
    return {"usd": usd, "jpy": jpy}

def estimate_embedding_cost(model: str, input_tokens: int, *, rate: float = DEFAULT_USDJPY) -> dict:
    if model not in EMBEDDING_PRICES_USD:
        raise ValueError(f"å˜ä¾¡æœªè¨­å®šã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«: {model}")
    usd = round((max(0, int(input_tokens)) / MILLION) * EMBEDDING_PRICES_USD[model], 6)
    jpy = usd_to_jpy(usd, rate=rate)
    return {"usd": usd, "jpy": jpy}

def estimate_transcribe_cost(model: str, seconds: float) -> dict:
    if model not in AUDIO_PRICES_USD_PER_MIN:
        raise ValueError(f"å˜ä¾¡æœªè¨­å®šã®éŸ³å£°ãƒ¢ãƒ‡ãƒ«: {model}")
    per_min = AUDIO_PRICES_USD_PER_MIN[model]
    minutes = max(0.0, seconds) / 60.0
    usd = round(per_min * minutes, 6)
    jpy = usd_to_jpy(usd)
    return {"usd": usd, "jpy": jpy}

# ====== ä½¿ç”¨é‡ã®æ¦‚ç®—ï¼ˆUIãƒ¬ãƒ³ãƒ€ï¼‰ ==============================================
def _model_prices_per_1k():
    """MODEL_PRICES_USDï¼ˆUSD/1M tokï¼‰ã‹ã‚‰ USD/1K tok ã‚’ä½œã‚‹"""
    return {
        m: {
            "in": float(p.get("in", 0.0)) / 1000.0,
            "out": float(p.get("out", 0.0)) / 1000.0,
        }
        for m, p in MODEL_PRICES_USD.items()
    }

def render_usage_summary(
    *,
    embedding_model: str,
    embedding_tokens: int,
    chat_model: str,
    chat_prompt_tokens: int,
    chat_completion_tokens: int,
    use_backend_openai: bool,
    title: str = "ğŸ“Š ä½¿ç”¨é‡ã®æ¦‚ç®—",
):
    """
    ä½¿ç”¨é‡/è²»ç”¨ã®æ¦‚ç®—ã‚’3ã‚«ãƒ©ãƒ ã§æç”»ã™ã‚‹ã€‚
    - embedding_tokens ãŒ 0 ã®å ´åˆã¯ Embedding ã‚’ 0 ã¨ã—ã¦æ‰±ã†
    - use_backend_openai ãŒ False ã®å ´åˆã¯ Chat ã‚’ 0 ã¨ã—ã¦æ‰±ã†
    """
    emb_cost = {"usd": 0.0, "jpy": 0.0}
    if embedding_tokens and embedding_model:
        emb_cost = estimate_embedding_cost(embedding_model, embedding_tokens)

    chat_cost = {"usd": 0.0, "jpy": 0.0}
    if use_backend_openai and chat_model and (chat_prompt_tokens or chat_completion_tokens):
        chat_cost = estimate_chat_cost(
            chat_model, ChatUsage(input_tokens=chat_prompt_tokens or 0, output_tokens=chat_completion_tokens or 0)
        )

    total_usd = float(emb_cost["usd"]) + float(chat_cost["usd"])
    total_jpy = usd_to_jpy(total_usd, rate=DEFAULT_USDJPY)

    st.markdown(f"### {title}")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("åˆè¨ˆ (JPY)", f"{total_jpy:,.2f} å††")
        st.caption(f"ç‚ºæ›¿ {DEFAULT_USDJPY:.2f} JPY/USD")
    with c2:
        st.write("**å†…è¨³ (USD)**")
        st.write(f"- Embedding: `${emb_cost['usd']:.6f}`")
        if use_backend_openai:
            st.write(f"- Chat: `${chat_cost['usd']:.6f}` (in={chat_prompt_tokens}, out={chat_completion_tokens})")
        st.write(f"- åˆè¨ˆ: `${total_usd:.6f}`")
    with c3:
        per_1k = _model_prices_per_1k()
        emb_per_1k = float(EMBEDDING_PRICES_USD.get(embedding_model, 0.0)) / 1000.0
        chat_in = float(per_1k.get(chat_model, {}).get("in", 0.0))
        chat_out = float(per_1k.get(chat_model, {}).get("out", 0.0))
        st.write("**å˜ä¾¡ (USD / 1K tok)**")
        st.write(f"- Embedding: `${emb_per_1k:.5f}`ï¼ˆ{embedding_model}ï¼‰")
        st.write(f"- Chat å…¥åŠ›: `${chat_in:.5f}`ï¼ˆ{chat_model}ï¼‰")
        st.write(f"- Chat å‡ºåŠ›: `${chat_out:.5f}`ï¼ˆ{chat_model}ï¼‰")

    # å‚ç…§ç”¨ã«è¿”ã™ï¼ˆå¿…è¦ãªã¨ãåˆ©ç”¨å¯èƒ½ï¼‰
    return {
        "embedding_usd": float(emb_cost["usd"]),
        "chat_usd": float(chat_cost["usd"]),
        "total_usd": float(total_usd),
        "total_jpy": float(total_jpy),
    }

# ====== ã“ã“ã‹ã‚‰è¿½åŠ ï¼šmeta.jsonl ã‹ã‚‰å®‰å…¨ã«æ¦‚ç®—ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ======

def _percentile(values: List[int], q: float) -> float:
    if not values:
        return 0.0
    if q <= 0:
        return float(min(values))
    if q >= 1:
        return float(max(values))
    s = sorted(values)
    idx = max(0, min(len(s)-1, int(math.ceil(q * len(s)) - 1)))
    return float(s[idx])

def summarize_embedding_cost_from_meta(
    meta_path: Path,
    model: str = "text-embedding-3-large",
    *,
    rate: float = DEFAULT_USDJPY,
    outlier_tok_threshold: int = 8192,
    include_source_paths: Optional[list[str]] = None,   # ç‰¹å®šã®PDFã ã‘ã«çµã‚‹
    created_after_iso: Optional[str] = None,            # ã‚ã‚‹æ™‚åˆ»ä»¥é™ã ã‘é›†è¨ˆ
) -> Dict[str, Any]:
    """
    meta.jsonl ã‚’èª­ã¿ã€chunk_len_tokens ã‚’åˆç®—ã—ã¦åŸ‹ã‚è¾¼ã¿ã‚³ã‚¹ãƒˆã‚’æ¦‚ç®—ã€‚
    åŒæ™‚ã«ã‚µãƒ‹ãƒ†ã‚£æƒ…å ±ã¨è­¦å‘Šã‚’è¿”ã™ã€‚

    include_source_paths : list[str]  â†’ source_path / path / file ãŒä¸€è‡´ã™ã‚‹è¡Œã ã‘ã«é™å®š
    created_after_iso    : str        â†’ "2025-10-15T12:34:56Z" ãªã©ã€‚æ–°è¦å®Ÿè¡Œä»¥é™ã«ä½œã‚‰ã‚ŒãŸè¡Œã ã‘

    Returns:
    {
      "model": str,
      "price_per_1M": float,
      "rate": float,
      "total_tokens": int,
      "n_chunks": int,
      "avg_tok": float, "p95_tok": float, "max_tok": int,
      "skipped_outliers": int,
      "had_chars_without_tokens": bool,
      "warnings": List[str],
      "usd": float, "jpy": float
    }
    """
    warnings: List[str] = []
    tokens_list: List[int] = []
    skipped_outliers = 0
    had_chars_without_tokens = False

    if not meta_path.exists():
        return {
            "model": model, "price_per_1M": EMBEDDING_PRICES_USD.get(model, 0.0),
            "rate": rate, "total_tokens": 0, "n_chunks": 0,
            "avg_tok": 0.0, "p95_tok": 0.0, "max_tok": 0,
            "skipped_outliers": 0, "had_chars_without_tokens": False,
            "warnings": ["meta.jsonl ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"],
            "usd": 0.0, "jpy": 0.0
        }

    with meta_path.open("r", encoding="utf-8") as f:
        for line in f:
            try:
                obj = json.loads(line)
            except Exception:
                continue

            # â”€â”€ â‘  ãƒ•ã‚¡ã‚¤ãƒ«åãƒ•ã‚£ãƒ«ã‚¿ï¼ˆinclude_source_pathsï¼‰â”€â”€
            if include_source_paths:
                src = obj.get("source_path") or obj.get("path") or obj.get("file")
                if not src or not any(src.endswith(p) or src == p for p in include_source_paths):
                    continue

            # â”€â”€ â‘¡ ä½œæˆæ™‚åˆ»ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆcreated_after_isoï¼‰â”€â”€
            if created_after_iso and (ca := obj.get("created_at")):
                if ca < created_after_iso:
                    continue

            # â”€â”€ â‘¢ ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±å–å¾— â”€â”€
            if "chunk_len_tokens" not in obj and "chunk_len_chars" in obj:
                had_chars_without_tokens = True

            tok = int(obj.get("chunk_len_tokens", 0))
            if tok < 0:
                continue
            if outlier_tok_threshold and tok > outlier_tok_threshold:
                skipped_outliers += 1
                continue

            tokens_list.append(tok)

    # â”€â”€ é›†è¨ˆ â”€â”€
    total_tokens = int(sum(tokens_list))
    n = len(tokens_list)
    avg_tok = (total_tokens / n) if n else 0.0

    def _percentile(values: List[int], q: float) -> float:
        if not values:
            return 0.0
        if q <= 0:
            return float(min(values))
        if q >= 1:
            return float(max(values))
        s = sorted(values)
        idx = max(0, min(len(s) - 1, int(math.ceil(q * len(s)) - 1)))
        return float(s[idx])

    p95_tok = _percentile(tokens_list, 0.95) if n else 0.0
    max_tok = max(tokens_list) if n else 0

    # â”€â”€ ãƒã‚§ãƒƒã‚¯ã¨è­¦å‘Š â”€â”€
    price_per_1M = EMBEDDING_PRICES_USD.get(model, 0.0)
    if price_per_1M <= 0:
        warnings.append(f"åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®å˜ä¾¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model}")
    if rate > 1000:
        warnings.append(f"ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆãŒç•°å¸¸ã«å¤§ãã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™: {rate:.2f} JPY/USD")
    if had_chars_without_tokens:
        warnings.append("`chunk_len_tokens` ãŒç„¡ã `chunk_len_chars` ã®ã¿ã®è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚"
                        "æ–‡å­—æ•°ã‚’ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¨ã—ã¦èª¤é›†è¨ˆã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    if skipped_outliers > 0:
        warnings.append(f"å¤–ã‚Œå€¤ãƒãƒ£ãƒ³ã‚¯ï¼ˆ>{outlier_tok_threshold} tokï¼‰ã‚’ {skipped_outliers} ä»¶ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

    # â”€â”€ ã‚³ã‚¹ãƒˆè¨ˆç®— â”€â”€
    est = estimate_embedding_cost(model, total_tokens, rate=rate)

    return {
        "model": model,
        "price_per_1M": price_per_1M,
        "rate": rate,
        "total_tokens": total_tokens,
        "n_chunks": n,
        "avg_tok": float(avg_tok),
        "p95_tok": float(p95_tok),
        "max_tok": int(max_tok),
        "skipped_outliers": skipped_outliers,
        "had_chars_without_tokens": had_chars_without_tokens,
        "warnings": warnings,
        "usd": float(est["usd"]),
        "jpy": float(est["jpy"]),
    }
