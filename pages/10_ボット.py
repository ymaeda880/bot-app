# pages/10_ãƒœãƒƒãƒˆ.pyï¼ˆå®Ÿè¡Œã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å‰Šé™¤ãƒ»åˆè¨ˆã‚³ã‚¹ãƒˆã®ã¿è¡¨ç¤ºãƒ»ã‚·ãƒ£ãƒ¼ãƒ‰UIå‰Šé™¤ç‰ˆï¼‰
from __future__ import annotations
from pathlib import Path
from typing import List, Tuple, Dict, Any, Set
import heapq
from itertools import count
import datetime as dt
import time
import json

import streamlit as st
import numpy as np
import sys

from config.path_config import PATHS
from config.sample_questions import SAMPLES2   # â˜… ã‚µãƒ³ãƒ—ãƒ«ã¯ SAMPLES2 ã‹ã‚‰
from lib.text_normalize import normalize_ja_text
from lib.prompts.bot_prompt import build_prompt
from lib.gpt_responder import GPTResponder, CompletionResult
from lib.rag.rag_utils import EmbeddingStore, NumpyVectorDB
from lib.costs import (
    estimate_chat_cost, estimate_embedding_cost, usd_to_jpy, DEFAULT_USDJPY, ChatUsage
)
from lib.openai_utils import count_tokens
from lib.bot_utils import (
    list_shard_dirs_openai, fmt_source, enrich_citations, citation_tag,
    parse_years, parse_pnos, norm_pno_forms, year_ok, pno_ok,
    scan_candidate_files, filters_caption,
)

_THIS = Path(__file__).resolve()
PROJECTS_ROOT = _THIS.parents[3]  # 3éšå±¤ä¸Š = projects/
if str(PROJECTS_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECTS_ROOT))

from common_lib.auth.auth_helpers import get_current_user_from_session_or_cookie
from common_lib.logs.jsonl_logger import JsonlLogger, sha256_short

from io import BytesIO
try:
    from docx import Document
    from docx.shared import Pt
    from docx.enum.text import WD_ALIGN_PARAGRAPH
except Exception:
    Document = None  # python-docx æœªå°å…¥æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨

# --- sys.path èª¿æ•´ï¼ˆcommon_lib ã¸åˆ°é”ï¼‰ ---
import sys
_THIS = Path(__file__).resolve()
APP_DIR = _THIS.parents[1]        # .../bot_app
PROJ_DIR = _THIS.parents[2]       # .../bot_project
MONO_ROOT = _THIS.parents[3]      # .../projects
for p in (MONO_ROOT, PROJ_DIR, APP_DIR):
    if str(p) not in sys.path:
        sys.path.insert(0, str(p))

# --- ãƒ­ã‚¬ãƒ¼ ---
_APP_DIR = Path(__file__).resolve().parents[1]
_PAGE_NAME = Path(__file__).stem
logger = JsonlLogger(app_dir=_APP_DIR, page_name=_PAGE_NAME)
INCLUDE_FULL_PROMPT_IN_LOG = True

VS_ROOT: Path = PATHS.vs_root
CHAT_MODEL = "gpt-5-mini"  # â˜… ãƒ¢ãƒ‡ãƒ«å›ºå®š

# ===== Word å‡ºåŠ› =====
def _build_docx(prompt_text: str, answer_text: str, meta: Dict[str, Any], filters: Dict[str, Any] | None = None) -> bytes:
    if Document is None:
        raise RuntimeError("python-docx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`pip install python-docx` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    doc = Document()

    title = doc.add_paragraph("Internal Bot å¿œç­”")
    title.runs[0].font.size = Pt(16)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER

    doc.add_paragraph("")
    m = doc.add_paragraph()
    m.add_run("Meta").bold = True
    doc.add_paragraph(f"User: {meta.get('user') or '(anonymous)'}")
    doc.add_paragraph(f"Model: {meta.get('chat_model')}")
    doc.add_paragraph(f"Detail: {meta.get('detail_label')} ({meta.get('detail')})")
    doc.add_paragraph(f"Max Tokens: {meta.get('max_tokens')}")
    doc.add_paragraph(f"Top-K: {meta.get('top_k')}")
    doc.add_paragraph(f"Generated At: {meta.get('ts_jst')}")

    if filters and any([filters.get("years"), filters.get("pnos"), filters.get("shards")]):
        doc.add_paragraph("")
        f_hdr = doc.add_paragraph("Filters"); f_hdr.runs[0].bold = True
        if filters.get("years"):
            doc.add_paragraph(f"year: {', '.join(map(str, filters['years']))}")
        if filters.get("pnos"):
            doc.add_paragraph(f"pno: {', '.join(filters['pnos'])}")
        if filters.get("shards"):
            doc.add_paragraph(f"shards: {', '.join(filters['shards'])}")

    doc.add_paragraph("")
    p_hdr = doc.add_paragraph("è³ªå•ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰"); p_hdr.runs[0].bold = True
    for ln in (prompt_text or "").splitlines():
        doc.add_paragraph(ln)

    doc.add_paragraph("")
    a_hdr = doc.add_paragraph("å›ç­”"); a_hdr.runs[0].bold = True
    for ln in (answer_text or "").splitlines():
        doc.add_paragraph(ln)

    bio = BytesIO(); doc.save(bio)
    return bio.getvalue()


# ===== UI =====
st.set_page_config(page_title="Chat Bot (Sharded) â€” ç°¡ç•¥ç‰ˆ", page_icon="ğŸ’¬", layout="wide")

col_title, col_user = st.columns([5, 2], vertical_alignment="center")
with col_title:
    st.title("ğŸ’¬ Internal Botï¼ˆç°¡ç•¥ç‰ˆï¼‰")
with col_user:
    current_user, _payload = get_current_user_from_session_or_cookie(st)
    if current_user:
        st.success(f"ãƒ­ã‚°ã‚¤ãƒ³ä¸­: **{current_user}**")
    else:
        st.warning("æœªãƒ­ã‚°ã‚¤ãƒ³ï¼ˆCookie æœªæ¤œå‡ºï¼‰")

if "q" not in st.session_state:
    st.session_state.q = ""

def _set_q(x: str) -> None:
    st.session_state.q = x or ""

with st.expander("â„¹ï¸ ã“ã®ãƒšãƒ¼ã‚¸ã®ä½¿ã„æ–¹", expanded=False):
    st.markdown("""
### 1) ä½•ãŒã§ãã‚‹ï¼Ÿ
- ç¤¾å†…PDFã‚’ãƒ™ã‚¯ãƒˆãƒ«DBã‹ã‚‰ **RAG æ¤œç´¢ï¼‹å›ç­”ç”Ÿæˆ** ã—ã¾ã™ã€‚
- **year / pno ãƒ•ã‚£ãƒ«ã‚¿** ã§ç¯„å›²ã‚’çµã‚Œã¾ã™ã€‚
- **ãƒ¢ãƒ‡ãƒ«ã¯å›ºå®šï¼ˆgpt-5-miniï¼‰**ã€**å›ç­”ç”Ÿæˆã¯å¸¸ã« OpenAI**ã€**å‡ºå…¸ã¯å¸¸ã« [S1] è¡¨è¨˜**ã§ã™ã€‚
- ç”Ÿæˆã—ãŸ **è³ªå•ï¼‹å›ç­”** ã‚’ **Wordï¼ˆ.docxï¼‰** ã§ä¿å­˜ã§ãã¾ã™ï¼ˆãƒ•ã‚£ãƒ«ã‚¿æƒ…å ±ã¤ãï¼‰ã€‚

### 2) ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆä¸»ãªè¨­å®šï¼‰
- **æ¤œç´¢ä»¶æ•°ï¼ˆTop-Kï¼‰**ã€**è©³ã—ã•**ã€**æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³**ã€**System Instruction**ã€**è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ï¼ˆé€æ¬¡/ä¸€æ‹¬ï¼‰**ã€**year / pno ãƒ•ã‚£ãƒ«ã‚¿**ã€‚
- å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«ã®é™å®šã‚„ã€è§£æ±ºãƒ‘ã‚¹/ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³è¡¨ç¤ºã¯æœ¬ãƒšãƒ¼ã‚¸ã§ã¯çœç•¥ã•ã‚Œã¦ã„ã¾ã™ã€‚

### 3) ä½¿ã„æ–¹ã®æµã‚Œ
1. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å¿…è¦ã«å¿œã˜ã¦è¨­å®šï¼ˆyear/pno ãªã©ï¼‰  
2. å…¥åŠ›æ¬„ã«è³ªå•ã‚’å…¥ã‚Œã¦ **é€ä¿¡**  
3. å›ç­”ã®ä¸‹ã« **å‡ºå…¸ï¼ˆ[S1]â€¦ï¼‰** ã¨ **å‚ç…§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ** ã‚’è¡¨ç¤º  
4. å¿…è¦ã«å¿œã˜ã¦ **Word ã§ä¿å­˜** ãƒœã‚¿ãƒ³ã‹ã‚‰ .docx ã‚’å‡ºåŠ›
    """)

st.divider()

# ----- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆæ¤œç´¢å¯¾è±¡ã‚·ãƒ£ãƒ¼ãƒ‰ UI ã¯å‰Šé™¤ï¼‰ -----
with st.sidebar:
    # st.page_link("app.py", label="ğŸ¤– appã¸æˆ»ã‚‹")



    st.header("è¨­å®š")

    chat_model = CHAT_MODEL  # å›ºå®šï¼ˆUI éè¡¨ç¤ºï¼‰

    top_k = st.slider("æ¤œç´¢ä»¶æ•°ï¼ˆTop-Kï¼‰", 1, 12, 6, 1)
    _detail_label = st.selectbox("è©³ã—ã•", ["ç°¡æ½”", "æ¨™æº–", "è©³ç´°", "è¶…è©³ç´°"], index=2)
    _detail_map = {"ç°¡æ½”": "concise", "æ¨™æº–": "standard", "è©³ç´°": "detailed", "è¶…è©³ç´°": "very_detailed"}
    detail = _detail_map[_detail_label]; detail_label = _detail_label

    max_tokens = st.slider("æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³", 1000, 40000, 12000, 500)
    # sys_inst = st.text_area("System Instruction", "ã‚ãªãŸã¯å„ªç§€ãªç¤¾å†…ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™.", height=80)
    # st.text_area ã¯å‰Šé™¤
    sys_inst = "ã‚ãªãŸã¯å„ªç§€ãªç¤¾å†…ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™."

    display_mode = st.radio("è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰", ["é€æ¬¡è¡¨ç¤ºï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼‰", "ä¸€æ‹¬è¡¨ç¤º"], index=0)

    st.divider(); st.subheader("year / pno ãƒ•ã‚£ãƒ«ã‚¿")
    years_input = st.text_input("yearï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šãƒ»ä»»æ„ï¼‰", value="", help="ä¾‹: 2019,2023")
    pnos_input  = st.text_input("pnoï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·, ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šãƒ»ä»»æ„ï¼‰", value="", help="ä¾‹: 010,045,120")

    years_sel: Set[int] = parse_years(years_input)
    pnos_raw: Set[str]  = parse_pnos(pnos_input)
    pnos_sel_norm: Set[str] = set()
    for p in pnos_raw:
        pnos_sel_norm |= norm_pno_forms(p)

    st.caption(
        f"year ãƒ•ã‚£ãƒ«ã‚¿: {sorted(list(years_sel)) or 'ï¼ˆæœªæŒ‡å®šï¼‰'} / "
        f"pno ãƒ•ã‚£ãƒ«ã‚¿: {sorted(list(pnos_sel_norm)) or 'ï¼ˆæœªæŒ‡å®šï¼‰'}"
    )
    st.caption("â€» æœªå…¥åŠ›ãªã‚‰å…¨ä»¶å¯¾è±¡ã€‚ã©ã¡ã‚‰ã‹/ä¸¡æ–¹ã‚’å…¥åŠ›ã—ãŸå ´åˆã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ã—ã¾ã™ã€‚")

    st.divider(); st.subheader("ğŸ§ª ã‚µãƒ³ãƒ—ãƒ«è³ªå•ï¼ˆSAMPLES2ï¼‰")
    cat_options = ["ï¼ˆæœªé¸æŠï¼‰"] + list(SAMPLES2.keys())
    cat = st.selectbox("ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ", cat_options, index=0)
    sample_options = ["ï¼ˆæœªé¸æŠï¼‰"] if cat == "ï¼ˆæœªé¸æŠï¼‰" else ["ï¼ˆæœªé¸æŠï¼‰"] + SAMPLES2.get(cat, [])
    sample = st.selectbox("ã‚µãƒ³ãƒ—ãƒ«è³ªå•ã‚’é¸æŠ", sample_options, index=0)
    st.button("â¬‡ï¸ ã“ã®è³ªå•ã‚’å…¥åŠ›æ¬„ã¸ã‚»ãƒƒãƒˆ", use_container_width=True,
              disabled=(sample in ("", "ï¼ˆæœªé¸æŠï¼‰")), on_click=lambda: _set_q(sample))

# ----- æœ¬æ–‡ -----
q = st.text_area("è³ªå•ã‚’å…¥åŠ›", value=st.session_state.q, height=100,
                 placeholder="ã“ã®ç¤¾å†…ãƒœãƒƒãƒˆã«è³ªå•ã—ã¦ãã ã•ã„â€¦")
if q != st.session_state.q:
    st.session_state.q = q

go = st.button("é€ä¿¡", type="primary")

if go and st.session_state.q.strip():
    # â–¼ ãƒ­ã‚°
    try:
        _prompt_text = st.session_state.q.strip()
        logger.append({
            "user": current_user or "(anonymous)",
            "action": "ask",
            "chat_model": chat_model,
            "detail_label": detail_label,
            "detail": detail,
            "cite": True,                 # å¸¸ã« Trueï¼ˆ[S1] ä¿ƒã—ï¼‰
            "max_tokens": int(max_tokens),
            "top_k": int(top_k),
            "preset": False,
            "prompt_hash": sha256_short(_prompt_text),
            **({"prompt": _prompt_text} if INCLUDE_FULL_PROMPT_IN_LOG else {}),
        })
    except Exception as _log_e:
        st.warning(f"ãƒ­ã‚°ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {_log_e}")

    try:
        # â˜… ã‚·ãƒ£ãƒ¼ãƒ‰ã¯ UI ãªã—ã§ã€Œå…¨ã‚·ãƒ£ãƒ¼ãƒ‰ã€ã‚’å¯¾è±¡
        vs_backend_dir = PATHS.vs_root / "openai"
        if not vs_backend_dir.exists():
            st.warning(f"ãƒ™ã‚¯ãƒˆãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆ{vs_backend_dir}ï¼‰ã€‚å…ˆã«ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        all_ids = [p.name for p in list_shard_dirs_openai(PATHS.vs_root)]
        shard_dirs = [vs_backend_dir / s for s in all_ids]
        shard_dirs = [p for p in shard_dirs if p.is_dir() and (p / "vectors.npy").exists()]
        if not shard_dirs:
            st.warning("æ¤œç´¢å¯èƒ½ãªã‚·ãƒ£ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            st.stop()

        # å€™è£œæŠ½å‡ºï¼ˆyear/pno ã§å‰å‡¦ç†ï¼‰
        cand_by_shard, cand_total = scan_candidate_files(shard_dirs, years_sel, pnos_sel_norm)
        if (years_sel or pnos_sel_norm) and cand_total == 0:
            st.warning("æŒ‡å®šã® year/pno ã«ä¸€è‡´ã™ã‚‹**å€™è£œãƒ•ã‚¡ã‚¤ãƒ«ãŒ 0 ä»¶**ã®ãŸã‚ã€æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã›ã‚“ã€‚æ¡ä»¶ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        st.caption(filters_caption(years_sel, pnos_sel_norm, cand_total if (years_sel or pnos_sel_norm) else None))

        # åŸ‹ã‚è¾¼ã¿
        question = normalize_ja_text(st.session_state.q)
        estore = EmbeddingStore(backend="openai")
        embedding_tokens = count_tokens(st.session_state.q, "text-embedding-3-large")
        qv = estore.embed([question]).astype("float32")

        # æ¤œç´¢ï¼ˆTopK ãƒãƒ¼ã‚¸ï¼‰
        K = int(top_k)
        heap_: List[Tuple[float, int, int, Dict[str, Any]]] = []
        tie = count()
        for shp in shard_dirs:
            try:
                vdb = NumpyVectorDB(shp)
                local_k = max(K * 10, 50) if (years_sel or pnos_sel_norm) else K
                hits = vdb.search(qv, top_k=local_k, return_="similarity")
                for h in hits:
                    if isinstance(h, tuple) and len(h) == 3:
                        row_idx, score, meta = h
                    else:
                        score, meta = h
                        row_idx = -1
                    md = dict(meta or {}); md["shard_id"] = shp.name
                    if not year_ok(md, years_sel): continue
                    if not pno_ok(md, pnos_sel_norm): continue

                    sc = float(score)
                    if len(heap_) < K:
                        heapq.heappush(heap_, (sc, next(tie), row_idx, md))
                    elif sc > heap_[0][0]:
                        heapq.heapreplace(heap_, (sc, next(tie), row_idx, md))
            except Exception as e:
                st.warning(f"ã‚·ãƒ£ãƒ¼ãƒ‰ {shp.name} ã®æ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼: {e}")

        raw_hits = [(rid, sc, md) for (sc, _tb, rid, md) in sorted(heap_, key=lambda x: x[0], reverse=True)]
        if not raw_hits:
            if years_sel or pnos_sel_norm:
                st.warning("æ¡ä»¶ã«ã¯åˆã†å€™è£œãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã—ãŸãŒã€ä¸Šä½ã‚¹ã‚³ã‚¢ã«å…¥ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"
                           "ğŸ‘‰ Top-K ã‚’å¢—ã‚„ã™ï¼ã‚¯ã‚¨ãƒªã‚’å…·ä½“åŒ–ã™ã‚‹ï¼ã‚·ãƒ£ãƒ¼ãƒ‰ã‚’çµã‚‹ã€ã®ã„ãšã‚Œã‹ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
            else:
                st.warning("è©²å½“ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.stop()

        # å›ç­”ç”Ÿæˆï¼ˆOpenAIå›ºå®šãƒ»å‡ºå…¸ä¿ƒã—ONï¼‰
        labeled = [
            f"[S{i}] {m.get('text', '')}\n[meta: {fmt_source(m)} / score={float(s):.3f}]"
            for i, (_rid, s, m) in enumerate(raw_hits, 1)
        ]
        prompt = build_prompt(
            question,
            labeled,
            sys_inst=sys_inst,
            style_hint=detail,
            cite=True,          # å¸¸ã« True
            strict=False
        )
        responder = GPTResponder()
        chat_prompt_tokens = chat_completion_tokens = 0

        if display_mode == "é€æ¬¡è¡¨ç¤ºï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼‰":
            st.subheader("ğŸ§  å›ç­”ï¼ˆé€æ¬¡è¡¨ç¤ºï¼‰")
            with st.chat_message("assistant"):
                st.write_stream(
                    responder.stream(
                        model=chat_model,
                        system_instruction=sys_inst,
                        user_content=prompt,
                        max_output_tokens=int(max_tokens),
                        on_error_text="Responses stream error."
                    )
                )
            answer = responder.final_text or ""
            chat_prompt_tokens = responder.usage.input_tokens
            chat_completion_tokens = responder.usage.output_tokens
        else:
            st.subheader("ğŸ§  å›ç­”ï¼ˆä¸€æ‹¬è¡¨ç¤ºï¼‰")
            with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦"):
                result: CompletionResult = responder.complete(
                    model=chat_model,
                    system_instruction=sys_inst,
                    user_content=prompt,
                    max_output_tokens=int(max_tokens)
                )
            answer = result.text or ""
            chat_prompt_tokens = result.usage.input_tokens
            chat_completion_tokens = result.usage.output_tokens
            st.write(enrich_citations(answer, raw_hits))

        # å‡ºå…¸å±•é–‹
        answer = enrich_citations(answer, raw_hits)
        import re as _re
        citations = _re.findall(r"\[S[^\]]+\]", answer)
        if citations:
            seen = []
            for c in citations:
                if c not in seen: seen.append(c)
            with st.expander("ğŸ“ å‡ºå…¸æ‹¡å¼µæ¸ˆã¿æœ€çµ‚ãƒ†ã‚­ã‚¹ãƒˆ", expanded=False):
                st.caption("ä»¥ä¸‹ã¯å›ç­”å†…ã®å‡ºå…¸ã‚¿ã‚°ã‚’æ•´ç†ã—ãŸä¸€è¦§ã§ã™ã€‚")
                st.markdown("### ğŸ“š å‡ºå…¸ï¼ˆå‡ºå…¸ã”ã¨ã«æ”¹è¡Œï¼‰")
                st.text("\n".join(seen))

        # å‚ç…§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        with st.expander("ğŸ” å‚ç…§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä¸Šä½ãƒ’ãƒƒãƒˆï¼‰", expanded=False):
            for i, (_rid, score, meta) in enumerate(raw_hits, 1):
                txt = str(meta.get("text", "") or "")
                label = fmt_source(meta)
                year = meta.get("year", "")
                pno = meta.get("pno", "") or meta.get("project_no", "")
                snippet = (txt[:1000] + "â€¦") if len(txt) > 1000 else txt
                st.markdown(
                    f"**[{citation_tag(i, meta)}] score={float(score):.3f}**  "
                    f"`{label}` â€” **year:** {year} / **pno:** {pno}\n\n{snippet}"
                )

        # ===== Word ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ =====
        try:
            JST = dt.timezone(dt.timedelta(hours=9), name="Asia/Tokyo")
            ts_jst = dt.datetime.now(JST).strftime("%Y-%m-%d %H:%M:%S %Z")
            meta_doc = {
                "user": current_user or "(anonymous)",
                "chat_model": chat_model,
                "detail_label": detail_label,
                "detail": detail,
                "max_tokens": int(max_tokens),
                "top_k": int(top_k),
                "ts_jst": ts_jst,
            }
            # ã‚·ãƒ£ãƒ¼ãƒ‰UIãŒç„¡ã„ã®ã§ filters_doc ã® shards ã¯ç©ºé…åˆ—ã§OK
            filters_doc = {
                "years": sorted(list(years_sel)) if years_sel else [],
                "pnos": sorted(list(pnos_sel_norm)) if pnos_sel_norm else [],
                "shards": [],   # æœ¬ãƒšãƒ¼ã‚¸ã¯å…¨ã‚·ãƒ£ãƒ¼ãƒ‰å›ºå®š
            }
            if Document is None:
                st.info("ğŸ“„ Word ä¿å­˜ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ `pip install python-docx` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            else:
                docx_bytes = _build_docx(st.session_state.q.strip(), answer or "", meta_doc, filters_doc)
                default_name = f"bot_answer_{dt.datetime.now(JST):%Y%m%d_%H%M%S}.docx"
                st.download_button(
                    "â¬‡ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‹å›ç­”ã‚’ Word ã§ä¿å­˜ (.docx)",
                    data=docx_bytes,
                    file_name=default_name,
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    use_container_width=True,
                )
        except Exception as _docx_e:
            st.warning(f"Word ä¿å­˜ã§ã‚¨ãƒ©ãƒ¼: {_docx_e}")

      # ===== åˆè¨ˆã‚³ã‚¹ãƒˆï¼ˆç°¡æ˜“è¡¨ç¤ºã®ã¿ï¼‰=====
        try:
            # åŸ‹ã‚è¾¼ã¿ã‚³ã‚¹ãƒˆï¼ˆdict: {"usd": float, "jpy": float}ï¼‰
            emb_cost = estimate_embedding_cost("text-embedding-3-large", embedding_tokens)

            # ãƒãƒ£ãƒƒãƒˆã‚³ã‚¹ãƒˆï¼ˆdict: {"usd": float, "jpy": float}ï¼‰
            chat_cost = estimate_chat_cost(
                chat_model,
                ChatUsage(input_tokens=chat_prompt_tokens or 0, output_tokens=chat_completion_tokens or 0)
            )

            total_usd = float(emb_cost["usd"]) + float(chat_cost["usd"])
            total_jpy = float(emb_cost["jpy"]) + float(chat_cost["jpy"])

            st.info(f"ğŸ“Š apiä½¿ç”¨æ–™é‡‘ã®æ¦‚ç®—ï¼š**Â¥{total_jpy:,.2f}**ï¼ˆ${total_usd:.4f}ï¼‰")

        except Exception as _cost_e:
            st.caption(f"ã‚³ã‚¹ãƒˆè¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ: {_cost_e}")


    except Exception as e:
        st.error(f"æ¤œç´¢/ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
else:
    st.info("è³ªå•ã‚’å…¥åŠ›ã—ã¦ã€é€ä¿¡ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã§ãã¾ã™ã€‚")
