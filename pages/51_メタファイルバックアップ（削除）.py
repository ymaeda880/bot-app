# pages/51_ãƒ¡ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆå‰Šé™¤ï¼‰.py
# ------------------------------------------------------------
# ğŸ—‘ï¸ ãƒ¡ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ãƒšãƒ¼ã‚¸
# - å‰Šé™¤ / åˆæœŸåŒ– / ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— / å¾©å…ƒ / å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•´ç†
# - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜å…ˆï¼š<é¸æŠã—ãŸ BACKUP_ROOT> / <backend> / <shard_id> / <timestamp>
# - è¿½åŠ æ©Ÿèƒ½:
#   1) ã™ã¹ã¦ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚’å³æ™‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
#   2) å¯¾è±¡ã‚·ãƒ£ãƒ¼ãƒ‰ã®ã¿å³æ™‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
#   3) ã€Œæœªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ—¥æ•°ã€ã—ãã„å€¤ã§ä¸€æ‹¬ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
#   4) ã‚·ãƒ£ãƒ¼ãƒ‰ã”ã¨å‰Šé™¤ï¼ˆãƒ•ã‚©ãƒ«ãƒ€å®Œå…¨å‰Šé™¤â†’ç©ºãƒ•ã‚©ãƒ«ãƒ€å†ä½œæˆï¼‰
#   5) å®Œå…¨åˆæœŸåŒ–ã«ã‚‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼†DELETEç¢ºèª
#   6) å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤ï¼ˆæœ€æ–°Nä»¶ / ã—ãã„å€¤æ—¥æ•°ï¼‰
# ------------------------------------------------------------
from __future__ import annotations
from pathlib import Path
from datetime import datetime, timezone
import json
import shutil
import os
import urllib.parse
import unicodedata
import numpy as np
import pandas as pd
import streamlit as st

from config.path_config import PATHS  # âœ… vs_root / backup_root ã‚’é›†ä¸­ç®¡ç†
from lib.vectorstore_utils import iter_jsonl  # æ—¢å­˜ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

# ğŸ” å¤–éƒ¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆlib ä¸‹ã¸åˆ‡ã‚Šå‡ºã—æ¸ˆã¿ï¼‰
from lib.backup_utils import (
    backup_all_local,
    list_backup_dirs_local,
    preview_backup_local,
    restore_from_backup_local,
    backup_age_days_local,
    cleanup_old_backups_keep_last,
    cleanup_old_backups_older_than_days,
)
from lib.processed_files_utils import remove_from_processed_files_selective

# ============================================================
# åŸºæœ¬ãƒ‘ã‚¹ï¼ˆconfig ã«åˆã‚ã›ã‚‹ï¼‰
# ============================================================
VS_ROOT: Path = PATHS.vs_root
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ¨™æº–ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆãƒ©ã‚¸ã‚ªã§åˆ‡æ›¿ï¼‰
BACKUP_ROOT: Path = PATHS.backup_root

# ============================================================
# åˆæœŸå­˜åœ¨ä¿è¨¼ï¼ˆåˆå›ã§ã‚‚å¤±æ•—ã—ãªã„ã‚ˆã†ã«ï¼‰
# ============================================================
try:
    BACKUP_ROOT.mkdir(parents=True, exist_ok=True)
except Exception:
    pass
(VS_ROOT / "openai").mkdir(parents=True, exist_ok=True)
(VS_ROOT / "local").mkdir(parents=True, exist_ok=True)

# ============================================================
# UI è¨­å®š
# ============================================================
st.set_page_config(page_title="51 ãƒ¡ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤", page_icon="ğŸ—‘ï¸", layout="wide")
st.title("ğŸ—‘ï¸ ãƒ¡ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»å‰Šé™¤ï¼ˆã‚·ãƒ£ãƒ¼ãƒ‰å˜ä½ï¼‰")

# å†’é ­ã®ç’°å¢ƒã‚µãƒãƒªï¼ˆæ”¹è¡Œã§è¦‹ã‚„ã™ãï¼‰
st.markdown(
    f"""
**VectorStore:** `{VS_ROOT}`  
**æ¨™æº–ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:** `{PATHS.backup_root}`  
**å¤–ä»˜ã‘SSDãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:** `{PATHS.backup_root2}`
    """,
    unsafe_allow_html=True,
)

st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯ **å‰Šé™¤ãƒ»åˆæœŸåŒ–ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—/å¾©å…ƒ** ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚ä½œæ¥­å‰ã«å¿…ãšãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")

# ============================================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼: ã‚·ãƒ£ãƒ¼ãƒ‰é¸æŠ
# ============================================================
with st.sidebar:
    st.header("å¯¾è±¡ã‚·ãƒ£ãƒ¼ãƒ‰")
    backend = st.radio("ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰", ["openai", "local"], index=0, horizontal=True, key="sb_backend")
    base_backend_dir = VS_ROOT / backend
    if not base_backend_dir.exists():
        st.error(f"{base_backend_dir} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    shard_dirs = sorted([p for p in base_backend_dir.iterdir() if p.is_dir()])
    shard_ids = [p.name for p in shard_dirs]
    shard_id = st.selectbox("å¯¾è±¡ã‚·ãƒ£ãƒ¼ãƒ‰", shard_ids if shard_ids else ["(ãªã—)"], key="sb_shard")
    if not shard_ids:
        st.error("ã‚·ãƒ£ãƒ¼ãƒ‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()

# ============================================================
# å¯¾è±¡ã‚·ãƒ£ãƒ¼ãƒ‰ã®ãƒ‘ã‚¹
# ============================================================
base_dir = base_backend_dir / shard_id
meta_path = base_dir / "meta.jsonl"
vec_path  = base_dir / "vectors.npy"
pf_path   = base_dir / "processed_files.json"

# ============================================================
# ğŸ” ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæ‹¡å¼µæ©Ÿèƒ½ï¼‰
# ============================================================
st.subheader("ğŸ›¡ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæ‹¡å¼µï¼‰")

# === ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜å…ˆã®é¸æŠï¼ˆæ¨™æº– or å¤–ä»˜ã‘SSDï¼‰ ===
dest_label = st.radio(
    "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜å…ˆ",
    ["æ¨™æº–ï¼ˆbackup_rootï¼‰", "å¤–ä»˜ã‘SSDï¼ˆbackup_root2ï¼‰"],
    horizontal=True,
    key="bak_dest"
)
# é¸æŠã«å¿œã˜ã¦ BACKUP_ROOT ã‚’åˆ‡æ›¿
BACKUP_ROOT = PATHS.backup_root if "æ¨™æº–" in dest_label else PATHS.backup_root2
try:
    BACKUP_ROOT.mkdir(parents=True, exist_ok=True)
except Exception:
    pass
st.caption(f"ç¾åœ¨ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜å…ˆ: `{BACKUP_ROOT}`")

col_a, col_b, col_c = st.columns(3)
with col_a:
    if st.button("âš¡ å¯¾è±¡ã‚·ãƒ£ãƒ¼ãƒ‰ã‚’å³æ™‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—", width="stretch", key="bak_one"):
        copied, bdir = backup_all_local(base_dir, BACKUP_ROOT, backend, shard_id)
        if copied:
            st.success(f"[{backend}/{shard_id}] ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {bdir}")
        else:
            st.warning(f"[{backend}/{shard_id}] ã‚³ãƒ”ãƒ¼å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¿å­˜å…ˆ: {bdir}")

with col_b:
    if st.button("âš¡ ã™ã¹ã¦ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚’å³æ™‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—", width="stretch", key="bak_all"):
        summary = []
        for sid in shard_ids:
            sdir = base_backend_dir / sid
            copied, bdir = backup_all_local(sdir, BACKUP_ROOT, backend, sid)
            summary.append((sid, len(copied), bdir))
        ok = [f"- {sid}: {n}é …ç›® -> {bdir}" for sid, n, bdir in summary]
        st.success("å³æ™‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†:\n" + "\n".join(ok))

with col_c:
    threshold = st.selectbox("æœªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ—¥æ•° ä»¥ä¸Šãªã‚‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—", [1, 2, 3, 7, 14, 30], index=2, key="bak_thr")
    if st.button("ğŸ—“ æ¡ä»¶ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ", width="stretch", key="bak_cond"):
        triggered, skipped = [], []
        for sid in shard_ids:
            age = backup_age_days_local(BACKUP_ROOT, backend, sid)
            if age is None or age >= float(threshold):
                sdir = base_backend_dir / sid
                copied, bdir = backup_all_local(sdir, BACKUP_ROOT, backend, sid)
                triggered.append((sid, age, len(copied), bdir))
            else:
                skipped.append((sid, age))
        msg = ""
        if triggered:
            msg += "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œï¼ˆé–¾å€¤è¶…é or æœªå®Ÿæ–½ï¼‰:\n" + "\n".join(
                f"- {sid}: age={('None' if age is None else f'{age:.2f}d')} -> {n}é …ç›® @ {bdir}"
                for sid, age, n, bdir in triggered
            )
        if skipped:
            if msg:
                msg += "\n\n"
            msg += "ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé–¾å€¤æœªæº€ï¼‰:\n" + "\n".join(f"- {sid}: age={age:.2f}d" for sid, age in skipped)
        st.info(msg or "å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

st.divider()

# ============================================================
# ğŸ§¹ å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®æ•´ç†ï¼ˆæœ€æ–°Nä»¶ / ã—ãã„å€¤æ—¥æ•°ï¼‰
# ============================================================
st.subheader("ğŸ§¹ å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®æ•´ç†")

# â˜… å¯¾è±¡ã‚¹ã‚³ãƒ¼ãƒ—ã‚’é¸æŠ
scope_label = st.radio(
    "å‰Šé™¤å¯¾è±¡ã‚¹ã‚³ãƒ¼ãƒ—",
    ["ç¾åœ¨ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã®ã¿", "å…¨ã‚·ãƒ£ãƒ¼ãƒ‰ï¼ˆbackendé…ä¸‹ã™ã¹ã¦ï¼‰"],
    horizontal=True,
    key="cleanup_scope"
)


c1, c2 = st.columns(2)
with c1:
    keep_last = st.number_input("ä¿æŒã™ã‚‹æœ€æ–°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•°", min_value=1, max_value=50, value=3, step=1, key="keep_last_bak")
    if st.button("ğŸ§¹ æœ€æ–°Nä»¶ã‚’æ®‹ã—ã¦å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤", width="stretch", key="btn_cleanup_keep_last"):
        targets = shard_ids if "å…¨ã‚·ãƒ£ãƒ¼ãƒ‰" in scope_label else [shard_id]
        all_deleted = []
        for sid in targets:
            deleted = cleanup_old_backups_keep_last(BACKUP_ROOT, backend, sid, keep_last=int(keep_last))
            all_deleted.extend(deleted)
        if all_deleted:
            st.success(f"ä»¥ä¸‹ã®å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤ã—ã¾ã—ãŸ ({len(all_deleted)} ä»¶):\n" +
                       "\n".join(f"- {d}" for d in all_deleted))
        else:
            st.info("å‰Šé™¤å¯¾è±¡ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


with c2:
    older_days = st.number_input("ã“ã®æ—¥æ•°ã‚ˆã‚Šå¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤", min_value=1, max_value=3650, value=90, step=1, key="older_days_bak")
    if st.button("ğŸ§¹ ã—ãã„å€¤æ—¥æ•°ã‚ˆã‚Šå¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤", width="stretch", key="btn_cleanup_older_than"):
        targets = shard_ids if "å…¨ã‚·ãƒ£ãƒ¼ãƒ‰" in scope_label else [shard_id]
        all_deleted = []
        for sid in targets:
            deleted = cleanup_old_backups_older_than_days(BACKUP_ROOT, backend, sid, older_than_days=int(older_days))
            all_deleted.extend(deleted)
        if all_deleted:
            st.success(f"ä»¥ä¸‹ã®å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤ã—ã¾ã—ãŸ ({len(all_deleted)} ä»¶):\n" +
                       "\n".join(f"- {d}" for d in all_deleted))
        else:
            st.info("å‰Šé™¤å¯¾è±¡ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


st.divider()

# ============================================================
# ğŸ“„ ç¾çŠ¶ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
# ============================================================
st.subheader("ğŸ“„ ç¾çŠ¶ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
rows = [dict(obj) for obj in iter_jsonl(meta_path)] if meta_path.exists() else []
if not rows:
    st.warning("ã“ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã«ã¯ meta.jsonl ãŒå­˜åœ¨ã—ãªã„ã‹ã€ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    df = pd.DataFrame(rows)
    if "file" not in df.columns:
        df["file"] = None
    st.caption(f"ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df):,}")
    st.dataframe(df.head(500), width="stretch", height=420)

st.divider()

# ============================================================
# ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆå€‹åˆ¥ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰
# ============================================================
st.subheader("ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆå€‹åˆ¥ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰")
bdirs = list_backup_dirs_local(BACKUP_ROOT, backend, shard_id)
if bdirs:
    sel_bdir_prev = st.selectbox("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", bdirs, format_func=lambda p: p.name, key="prev_bdir")
    if sel_bdir_prev:
        st.dataframe(preview_backup_local(sel_bdir_prev), width="stretch", height=180)
else:
    st.caption("ã¾ã ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

st.divider()

# ============================================================
# ğŸ§¹ é¸æŠãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆprocessed_files ã®æ‰±ã„ã‚’ãƒ©ã‚¸ã‚ªã§é¸æŠï¼‰
# ============================================================
st.subheader("ğŸ§¹ é¸æŠãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤")
if rows:
    files = sorted(pd.Series([r.get("file") for r in rows if r.get("file")]).unique().tolist())
    c1, c2 = st.columns([2, 1])
    with c1:
        target_files = st.multiselect("å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆyear/file.pdf ãªã©ï¼‰", files, key="sel_targets")
    with c2:
        pf_mode = st.radio(
            "processed_files.json ã®å‡¦ç†",
            ["é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¶ˆã™ï¼ˆæ—¢å®šï¼‰", "å®Œå…¨ãƒªã‚»ãƒƒãƒˆï¼ˆå…¨å‰Šé™¤ï¼‰", "å¤‰æ›´ã—ãªã„"],
            index=0,
            key="pf_mode",
        )
        confirm_del = st.checkbox("å‰Šé™¤ã«åŒæ„ã—ã¾ã™", key="confirm_selective")

    if st.button(
        "ğŸ§¹ å‰Šé™¤å®Ÿè¡Œ",
        type="primary",
        width="stretch",
        disabled=not (target_files and confirm_del),
        key="btn_selective_delete",
    ):
        try:
            # ç›´å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            copied, bdir = backup_all_local(base_dir, BACKUP_ROOT, backend, shard_id)

            # meta.jsonl å†æ§‹ç¯‰ + vectors.npy åŒæœŸ
            keep_lines, keep_vec_indices = [], []
            removed_meta, valid_idx = 0, 0
            target_set = set(target_files)

            if meta_path.exists():
                with meta_path.open("r", encoding="utf-8") as f:
                    for raw in f:
                        s = raw.strip()
                        if not s:
                            continue
                        try:
                            obj = json.loads(s)
                        except Exception:
                            keep_lines.append(raw)  # å£Šã‚Œè¡Œã¯ä¿å…¨
                            continue
                        fname = obj.get("file") if isinstance(obj, dict) else None
                        if fname in target_set:
                            removed_meta += 1
                            valid_idx += 1
                            continue
                        keep_lines.append(json.dumps(obj, ensure_ascii=False) + "\n")
                        keep_vec_indices.append(valid_idx)
                        valid_idx += 1
                with meta_path.open("w", encoding="utf-8") as f:
                    f.writelines(keep_lines)

            removed_vecs = 0
            if vec_path.exists():
                vecs = np.load(vec_path)
                if vecs.ndim == 2:
                    new_vecs = vecs[keep_vec_indices] if keep_vec_indices else np.empty((0, vecs.shape[1]))
                    removed_vecs = vecs.shape[0] - new_vecs.shape[0]
                    np.save(vec_path, new_vecs)

            # processed_files.json ã®å‡¦ç†ï¼ˆãƒ©ã‚¸ã‚ªé¸æŠï¼‰
            pf_msg = ""
            if pf_mode == "å®Œå…¨ãƒªã‚»ãƒƒãƒˆï¼ˆå…¨å‰Šé™¤ï¼‰":
                if pf_path.exists():
                    pf_path.unlink()
                pf_msg = "- processed_files.json: å‰Šé™¤ï¼ˆå®Œå…¨ãƒªã‚»ãƒƒãƒˆï¼‰\n"

            elif pf_mode == "é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¶ˆã™ï¼ˆæ—¢å®šï¼‰":
                if pf_path.exists():
                    before, after, removed_pf, removed_list = remove_from_processed_files_selective(
                        pf_path, target_files
                    )
                    if removed_pf > 0:
                        st.success(
                            "processed_files.json ã‚’æ›´æ–°ã—ã¾ã—ãŸ:\n"
                            f"- é™¤å¤–æ•°: {removed_pf} ä»¶ (before={before}, after={after})\n"
                            f"- é™¤å¤–ã•ã‚ŒãŸé …ç›®ã®ä¾‹: {removed_list}"
                        )
                    else:
                        st.warning(
                            "processed_files.json ã«ä¸€è‡´ã™ã‚‹é …ç›®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"
                            "ï¼ˆãƒ•ãƒ«/ç›¸å¯¾/basename/stemãƒ»NFKCãƒ»URLãƒ‡ã‚³ãƒ¼ãƒ‰ãƒ»åŒºåˆ‡ã‚Šçµ±ä¸€ã§ç…§åˆã—ã¦ã„ã¾ã™ï¼‰"
                        )
                else:
                    pf_msg = "- processed_files.json: è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆå‡¦ç†ã‚¹ã‚­ãƒƒãƒ—ï¼‰\n"

            else:  # "å¤‰æ›´ã—ãªã„"
                pf_msg = "- processed_files.json: å¤‰æ›´ãªã—\n"

            st.success(
                "å‰Šé™¤å®Œäº† âœ…\n"
                f"- meta.jsonl: {removed_meta} è¡Œå‰Šé™¤\n"
                f"- vectors.npy: {removed_vecs} è¡Œå‰Šé™¤\n"
                f"{pf_msg}"
                f"- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {bdir}"
            )
        except Exception as e:
            st.error(f"å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

st.divider()

# ============================================================
# ğŸ—‚ï¸ ã‚·ãƒ£ãƒ¼ãƒ‰ã”ã¨å‰Šé™¤ï¼ˆãƒ•ã‚©ãƒ«ãƒ€å®Œå…¨å‰Šé™¤ï¼‰
# ============================================================
st.subheader("ğŸ—‚ï¸ ã‚·ãƒ£ãƒ¼ãƒ‰ã”ã¨å‰Šé™¤ï¼ˆãƒ•ã‚©ãƒ«ãƒ€å®Œå…¨å‰Šé™¤ï¼‰")

def _dir_stats(d: Path) -> tuple[int, int]:
    if not d.exists():
        return (0, 0)
    n, total = 0, 0
    for p in d.rglob("*"):
        if p.is_file():
            n += 1
            try:
                total += p.stat().st_size
            except Exception:
                pass
    return n, total

if base_dir.exists():
    cnt, total = _dir_stats(base_dir)
    st.caption(f"ã“ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€é…ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°: **{cnt:,}** / åˆè¨ˆã‚µã‚¤ã‚º: **{total:,} bytes**")
else:
    st.caption("ã“ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")

colx, coly = st.columns([2, 1])
with colx:
    do_backup_before_shard_delete = st.checkbox(
        "å‰Šé™¤å‰ã«æ¨™æº–ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆmeta/vectors/processedï¼‰ã‚’ä½œæˆã™ã‚‹",
        value=True,
        key="sharddel_backup",
    )
    confirm_shard_del = st.checkbox("ã‚·ãƒ£ãƒ¼ãƒ‰ã”ã¨å‰Šé™¤ã«åŒæ„ã—ã¾ã™ï¼ˆå…ƒã«æˆ»ã›ã¾ã›ã‚“ï¼‰", key="sharddel_confirm")
with coly:
    typed = st.text_input("ã‚¿ã‚¤ãƒ—ç¢ºèªï¼šDELETE ã¨å…¥åŠ›", value="", key="sharddel_typed")

if st.button(
    "ğŸ—‚ï¸ ã‚·ãƒ£ãƒ¼ãƒ‰ã”ã¨å‰Šé™¤ã‚’å®Ÿè¡Œ",
    type="secondary",
    width="stretch",
    disabled=not (confirm_shard_del and typed.strip().upper() == "DELETE"),
    key="sharddel_exec",
):
    try:
        if do_backup_before_shard_delete and base_dir.exists():
            copied, bdir = backup_all_local(base_dir, BACKUP_ROOT, backend, shard_id)
            st.info(f"äº‹å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {bdir} / ã‚³ãƒ”ãƒ¼: {', '.join(copied) if copied else 'ãªã—'}")

        if base_dir.exists():
            shutil.rmtree(base_dir)
        base_dir.mkdir(parents=True, exist_ok=True)
        st.success(f"ã‚·ãƒ£ãƒ¼ãƒ‰ `{backend}/{shard_id}` ã‚’å‰Šé™¤ï¼ˆãƒ•ã‚©ãƒ«ãƒ€å†ä½œæˆæ¸ˆã¿ï¼‰")
    except Exception as e:
        st.error(f"ã‚·ãƒ£ãƒ¼ãƒ‰å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

st.divider()

# ============================================================
# ğŸ¯ year/pno ã§å‰Šé™¤
# ============================================================
st.subheader("ğŸ¯ year / pno ã§å‰Šé™¤")

if rows:
    years = sorted(set(str(r.get("year")) for r in rows if r.get("year")))
    pnos = sorted(set(str(r.get("pno")) for r in rows if r.get("pno")))

    c1, c2 = st.columns(2)
    with c1:
        sel_year = st.selectbox("å¯¾è±¡ year", ["(æœªé¸æŠ)"] + years, key="sel_year")
    with c2:
        sel_pno = st.selectbox("å¯¾è±¡ pno", ["(æœªé¸æŠ)"] + pnos, key="sel_pno")

    confirm_yp = st.checkbox("å‰Šé™¤ã«åŒæ„ã—ã¾ã™ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¨å¥¨ï¼‰", key="confirm_yearpno")

    if st.button("ğŸ§¹ year/pno æŒ‡å®šå‰Šé™¤ã‚’å®Ÿè¡Œ", type="primary", width="stretch", disabled=not confirm_yp, key="btn_del_yearpno"):
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            copied, bdir = backup_all_local(base_dir, BACKUP_ROOT, backend, shard_id)

            keep_lines, keep_vec_indices = [], []
            removed_meta, valid_idx = 0, 0

            if meta_path.exists():
                with meta_path.open("r", encoding="utf-8") as f:
                    for raw in f:
                        s = raw.strip()
                        if not s:
                            continue
                        try:
                            obj = json.loads(s)
                        except Exception:
                            keep_lines.append(raw)
                            continue

                        yr = str(obj.get("year", ""))
                        pno = str(obj.get("pno", ""))
                        # â˜… year/pno ãŒä¸€è‡´ã™ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤
                        if (sel_year != "(æœªé¸æŠ)" and yr != sel_year):
                            keep_lines.append(json.dumps(obj, ensure_ascii=False) + "\n")
                            keep_vec_indices.append(valid_idx)
                        elif (sel_pno != "(æœªé¸æŠ)" and pno != sel_pno):
                            keep_lines.append(json.dumps(obj, ensure_ascii=False) + "\n")
                            keep_vec_indices.append(valid_idx)
                        else:
                            removed_meta += 1
                        valid_idx += 1

                with meta_path.open("w", encoding="utf-8") as f:
                    f.writelines(keep_lines)

            # vectors.npy åŒæœŸ
            removed_vecs = 0
            if vec_path.exists():
                vecs = np.load(vec_path)
                if vecs.ndim == 2:
                    new_vecs = vecs[keep_vec_indices] if keep_vec_indices else np.empty((0, vecs.shape[1]))
                    removed_vecs = vecs.shape[0] - new_vecs.shape[0]
                    np.save(vec_path, new_vecs)

            st.success(
                f"å‰Šé™¤å®Œäº† âœ…\n"
                f"- year={sel_year}, pno={sel_pno} ã«ä¸€è‡´ã™ã‚‹ãƒ¡ã‚¿ã‚’å‰Šé™¤\n"
                f"- meta.jsonl: {removed_meta} è¡Œå‰Šé™¤\n"
                f"- vectors.npy: {removed_vecs} è¡Œå‰Šé™¤\n"
                f"- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {bdir}"
            )
        except Exception as e:
            st.error(f"å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

st.divider()

# ============================================================
# ğŸ—‘ï¸ å®Œå…¨åˆæœŸåŒ–ï¼ˆ3ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‰Šé™¤ï¼šmeta.jsonl / vectors.npy / processed_files.jsonï¼‰
# ============================================================
st.subheader("ğŸ—‘ï¸ å®Œå…¨åˆæœŸåŒ–")

targets = [
    ("meta.jsonl", meta_path),
    ("vectors.npy", vec_path),
    ("processed_files.json", pf_path),
]
present = [(name, p, (p.stat().st_size if p.exists() and p.is_file() else 0)) for name, p in targets if p.exists()]
total_bytes = sum(s for _, _, s in present)

if present:
    lines = [f"- {name}: {p} ({size:,} bytes)" for name, p, size in present]
    st.caption("å‰Šé™¤å¯¾è±¡ï¼ˆå­˜åœ¨ã—ã¦ã„ã‚‹ã‚‚ã®ã®ã¿ï¼‰:\n" + "\n".join(lines))
    st.caption(f"åˆè¨ˆã‚µã‚¤ã‚º: **{total_bytes:,} bytes**")
else:
    st.caption("å‰Šé™¤å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆmeta / vectors / processedï¼‰ã€‚")

col_init_l, col_init_r = st.columns([2, 1])
with col_init_l:
    do_backup_before_wipe = st.checkbox(
        "å‰Šé™¤å‰ã«æ¨™æº–ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆmeta/vectors/processedï¼‰ã‚’ä½œæˆã™ã‚‹",
        value=True,
        key="wipe_backup",
    )
    confirm_wipe = st.checkbox("å®Œå…¨åˆæœŸåŒ–ã«åŒæ„ã—ã¾ã™ï¼ˆå…ƒã«æˆ»ã›ã¾ã›ã‚“ï¼‰", key="wipe_confirm")
with col_init_r:
    typed_init = st.text_input("ã‚¿ã‚¤ãƒ—ç¢ºèªï¼šDELETE ã¨å…¥åŠ›", value="", key="wipe_typed")

if st.button(
    "ğŸ—‘ï¸ åˆæœŸåŒ–å®Ÿè¡Œ",
    type="secondary",
    width="stretch",
    disabled=not (confirm_wipe and typed_init.strip().upper() == "DELETE"),
    key="wipe_execute",
):
    try:
        if do_backup_before_wipe:
            copied, bdir = backup_all_local(base_dir, BACKUP_ROOT, backend, shard_id)
            st.info(f"äº‹å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {bdir} / ã‚³ãƒ”ãƒ¼: {', '.join(copied) if copied else 'ãªã—'}")

        deleted = []
        for name, p in targets:
            if p.exists():
                p.unlink()
                deleted.append(f"{name}: {p}")

        if deleted:
            st.success("å®Œå…¨åˆæœŸåŒ–ã—ã¾ã—ãŸ:\n" + "\n".join(f"- {x}" for x in deleted))
        else:
            st.info("å‰Šé™¤å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    except Exception as e:
        st.error(f"å®Œå…¨åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

st.divider()

# ============================================================
# â™»ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒ
# ============================================================
st.subheader("â™»ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒ")
bdirs = list_backup_dirs_local(BACKUP_ROOT, backend, shard_id)
if not bdirs:
    st.info("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
else:
    sel_bdir_restore = st.selectbox("å¾©å…ƒã™ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’é¸æŠ", bdirs, format_func=lambda p: p.name, key="restore_bdir")
    if sel_bdir_restore:
        st.dataframe(preview_backup_local(sel_bdir_restore), width="stretch", height=160)
        ok_restore = st.checkbox("å¾©å…ƒã«åŒæ„ã—ã¾ã™ï¼ˆç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¸Šæ›¸ãã•ã‚Œã¾ã™ï¼‰", key="restore_ok")
        if st.button("â™»ï¸ å¾©å…ƒå®Ÿè¡Œ", type="primary", width="stretch", disabled=not ok_restore, key="restore_exec"):
            try:
                restored, missing = restore_from_backup_local(base_dir, sel_bdir_restore)
                msg = "å¾©å…ƒå®Œäº† âœ…\n" + "\n".join(f"- {x}" for x in restored)
                if missing:
                    msg += "\n\nå­˜åœ¨ã—ãªã‹ã£ãŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é …ç›®:\n" + "\n".join(f"- {x}" for x in missing)
                st.success(msg)
            except Exception as e:
                st.error(f"å¾©å…ƒä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
